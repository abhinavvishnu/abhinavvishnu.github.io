<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<title>Abhinav Vishnu, AMD Research</title>
<link rel="stylesheet" type="text/css" href="style.css" media="screen" />
<style type="text/css">
<!--
.style3 {font-size: medium}
.style9 {font-size: 10px}
.style13 {font-size: small}
-->
</style>
</head>
<body>
<div id="header">
<h1><a href="http://abhinavvishnu.github.io">Abhinav Vishnu, AMD Research</a></h1>
</div>
<div id="content">
<div id="right">
<table width="850" border="0">
  <tr>
    
    <th width="120" scope="col"><img src="abhinav_vishnu.jpeg" alt=""
    width="120" height="160" />    </th>
    <td width="600" align="left" scope="col"><h2><span style="color: rgb(153,
							0, 0);">Abhinav Vishnu</span></h2>
			<h3><a href="http://abhinavvishnu.github.io/abhinav_vishnu_cv.pdf">(CV)</a>
			<a href="http://dblp.uni-trier.de/pers/hd/v/Vishnu:Abhinav">(DBLP)</a>
			<a href=https://scholar.google.com/citations?user=PgLExogAAAAJ&hl=en">(Google Scholar)</a></h3>
      <!-- <h2>  ( <img src="resource/name.gif" alt="" width="70" height="24"> -->
      <!-- 		   ) </h2> -->
      <!-- <span class="style13" style="color: rgb(153,0,0);">(<img src="resource/name.gif" alt="" width="52" height="20">)</span><br> -->
	<span class="style13"></span><br>
	<span class="style13"> Principal Member of Technical Staff,<br>
	 <a href="https://www.amd.com/en-us/who-we-are/corporate-information/research">AMD Research</a><br \>
(This is my personal webpage. It is not endorsed by my current or previous employers.)
</span><br>
</td>

</th></tr>
</table>
<p>
I am a Principal Member of Technical Staff (PMTS) at AMD Research. 
<br>
<br>

My research interests are at a cross-section of designing novel Deep Learning (DL)/Machine Learning (ML) algorithms that scale-up (on a compute node) and scale-out (on clusters/supercomputers) (TACO'18, EuroMPI/USA'17, BigData'16, HiPC'16, Arxiv'16). I am also interested in applying DL/ML approaches to problems in HPC (HPDC'18, iWAPT'18, IPDPS'16), Chemistry (KDD'18, WACV'18, JCC'17), and question routing (ECML-PKDD'18). 

<br>
<br>

Previously, I have been involved in designing scalable programming models and communication subsystems A by-product of our research in PGAS programming models (<a href="https://github.com/GlobalArrays/ga/wiki"> Global Arrays </a>) is Communication Runtime for Extreme Scale (<a href="http://hpc.pnl.gov/comex">ComEx</a>). ComEx is released with Global Arrays. During PhD, I was heavily involved in designing MPI runtimes with InfiniBand and other interconnects. My research is integrated with <a
    href="http://mvapich.cse.ohio-state.edu">MVAPICH</a> (300K downloads in last decade!!).  

<h2><span style="color: rgb(153, 0, 0);">Available Positions</span></h2><p>
<li><strong>I am looking for students and post-doctorate RAs with passion for Deep Learning and large-scale computing. Please contact me for more details at abhinav DOT vishnu AT amd DOT com</strong>
</p>

<h2><span style="color: rgb(153, 0, 0);">Research Interests</span></h2>
<ol>
		<li>Extreme Scale Machine Learning and Data Mining (MLDM) Algorithms</li>
		<li>Scalable, Fault tolerant and Energy Efficient Runtime Systems</li>
		<li>Applications of Machine Learning such as HPC, Chemistry, Performance, Fault and Energy Modeling</li>
</ol>
</p>


<h2>Recent Professional Activities</h2>
<ol>
		<li><strong>Journal Editorships:</strong> 
		 ParCo'18 (Special Issues on Programming Models and Systems Software), ParCo'16, ParCo'15 (Special Issue on Energy Efficient Supercomputing), ParCo'15 (Special Issue on Programming Models and Systems Software), ParCo'13 (Special Issue on Programming Models and Systems Software), JoSC'13 (Special Issue on Systems Sofwtare)
		<li><strong>Program Committees:</strong> 
		SC'18, HiPC'18, ESPM2'18, GraML'18, FTXS'18, ICPP'17,IPDPS'17,ESPM2'16, COM-HPC'16,CCGrid16, IPDPS'16, HiPC'16, FTXS'15, HiPC'15, CCGrid'14, IPDPS'14, HiPC'14, Cluster'15, Cluster'12, Cluster'10, ICPP'12, NCP'12, PASA'13, CASS'13, CASS'12

<li><strong>Organizing Committees:</strong> 
		P2S2'17, P2S2'16, P2S2'15 (Program co-chair), ParLearning'14 (Program co-chair), P2S2'14 (Program co-chair), 
		P2S2'13 (Program co-chair), P2S2'12 (Program co-chair), E2SC'15 (Publicity chair), E2SC'14 (Proceedings chair)
		</li>
  <li></li>
  <li><strong>Panelists:</strong> DOE Machine Learning Workshop'2015, DOE SBIR'11</li>
</ol>


<h2><span style="color: rgb(153, 0, 0);">Select Recent Publications</span><span class="style3">
</h2>


<blockquote>
  <p>
    <strong>[ICMLA'18]</strong> "SMILES2prop: An Interpretable General-Purpose Deep Neural Network for Predicting Chemical Properties", G. Goh, C. Siegel, A. Vishnu, and N. Hodas.
    <br>
    <strong>[RSI'18]</strong> "Improving Underwater Localization with Machine Learning
", L. Rauchenstein, A. Vishnu, X. Li, and Z. Deng.
    <br>
    <strong>[ECML-PKDD'18]</strong> "ColdRoute: Routing Cold Questions in Stack Exchange Sites
", J. Sun, S. Parthsarathy, A. Vishnu, C. Siegel and A. Chakrabarti.
    <br>
    <strong>[KDD'18]</strong> "Using Rule-Based Labels for Weak Supervised Learning
", G. Goh, C. Siegel, A. Vishnu, and N. Hodas.
    <br>
    <strong>[HPDC'18]</strong> "Desh: Deep Learning for System Health Prediction of Lead Times to Failure in HPC", A. Das, F. Mueller, C. Siegel, and A. Vishnu.
    <br>
    <strong>[TACO'18]</strong> "NUMA-Caffe: NUMA-Aware Deep Learning Neural Networks
", P. Roy, S. Song, S. Krishnamoorthy, A. Vishnu, D. Sengputa, and X. Liu.
    <br>
	<strong>[EuroMPI/USA'17]</strong> "What does fault tolerant Deep Learning need from MPI?", V. Amatya, A. Vishnu, C. Siegel and J. Daily.
	<br>	
	<strong>[ICS'17]</strong> "ScalaFSM: Enabling Scalability-Sensitive Speculative Parallelization for FSM Computations", J. Qiu, Z. Zhao, B. Wu, A. Vishnu, and S. Song.
	<br>	
	<strong>[JCC'17]</strong> "Deep Learning on Computational Chemistry", G. Goh, A. Vishnu and N. Hodas.
	<br>	
	<strong>[IPDPS'17]</strong> "Generating Performance Models for Irregular Applications", R. Friese, N. Tallent, A. Vishnu, D. Kerbyson and A. Hoisie.
	<br>	
	<strong>[BigData'16, Arxiv'16 [2]]</strong> "Adaptive Neuron Apoptosis for Accelerating Deep Learning on Large Scale Systems", C. Siegel, J. Daily, and A. Vishnu.
	<br>	
	<strong>[HiPC'16]</strong> "Fault Tolerant Frequent Pattern Mining", S. Shohdy, A. Vishnu, and G. Agrawal.
	<br>	
	<strong>[ICPADS'16]</strong> "Accelerating Deep Learning with Shrinkage and Recall", S. Zheng, A. Vishnu, and C. Ding.
	<br>	
	<strong>[ICPP'16]</strong> "Fault Tolerant Support Vector Machines", S. Shohdy, A. Vishnu, and G. Agrawal.
	<br>	
	<strong>[Arxiv'16 [1]]</strong> "Distributed TensorFlow with MPI", C. Siegel, J. Daily, and A. Vishnu.
	<br>	
	<strong>[IPDPS'16]</strong> "Fault Modeling of Extreme Scale Applications
	using Machine Learning", A. Vishnu, H. v. Dam, N. Tallent, D. Kerbyson and
	A. Hoisie.
	<br>	
	<strong>[SC'15]</strong> "A Case for Application-Oblivious Energy Efficient
	MPI Runtime", A. Venkatesh, A. Vishnu, K. Hamidouche, N. Tallent, D.
	Kerbyson, A. Hoisie, D. Panda. (Best Student Paper Finalist, SC15)
	<br>	
	<strong>[PPoPP'15]</strong> "Diagnosing the Causes and Severity of
	One-sided Message Contention", N. Tallent, A. Vishnu, H. v. Dam, J. Daily,
	D.  Kerbyson, and A. Hoisie 
	(Please refer to CV for a complete list of publications)

</blockquote>



<blockquote>
  <p><br>
        </p>
</blockquote>
</div>
	
<div id="left">
	<div class="box">
			<h2><small style="color: rgb(153, 0, 0);">News
			    :</small></h2>
<small>
		<p><strong>5/2018 </strong>: We have a paper accepted in ICMLA'18! Many congraultations to Garrett Goh and Team!!
		<p><strong>8/2018 </strong>: I have been invited to serve on SC'19 Program Committee! 
		<p><strong>8/2018 </strong>: I have been invited to serve on CCGrid'19 Program Committee! 
		<p><strong>7/2018 </strong>: We have a paper accepted in Review of Scientific Instruments'18! Many congraultations to Lynn Rauchenstein and Team!!
		<p><strong>6/2018 </strong>: We have a paper accepted in ECML-PKDD'18! Many congraultations to Jiankai Sun and Team!!
		<p><strong>5/2018 </strong>: We have a paper accepted in KDD'18! Many congraultations to Garrett Goh and Team!!
		<p><strong>5/2018 </strong>: I have been invited to serve on ESPM2@SC'18 Program Committee! 
		<p><strong>4/2018 </strong>: I have been invited to serve on FTXS@SC'18 Program Committee! 
		<p><strong>4/2018 </strong>: I have been invited to serve on HiPC'18 Program Committee! 
		<p><strong>3/2018 </strong>: We have a paper accepted in HPDC'18!
		<p><strong>3/2018 </strong>: I am serving as a Program co-chair for GraML'18 workshop!
    <p><strong>3/2018 </strong>: Our paper on <strong>Effective Machine Learning Based Format Selection and Performance Modeling for SpMV on GPUs</strong> has been accepted by iWAPT'18!
		<p><strong>3/2018 </strong>: I am serving as a Program co-chair for GraML'18 workshop!
		<p><strong>2/2018 </strong>: I have been invited to serve on SC'18 Program Committee! 
		<p><strong>1/2018 </strong>: Our paper on <strong>NUMA-Caffe: NUMA-Aware Deep Learning Neural Networks</strong> is accepted for publication at <strong>TACO</strong>.!!
		<p><strong>1/2018 </strong>: Our paper on <strong>How Much Chemistry Does a Deep Neural Network Need to Know to Make Accurate Predictions?</strong> is accepted for publication at <strong>Winter Applications for Applications of Computer Vision </strong>.!!
		<p><strong>12/2017 </strong>: I have joined AMD Research as a Principal Member of Technical Staff. 
		<p><strong>7/2017 </strong>: Our paper on <strong>What does fault tolerant Deep Learning need from MPI?</strong> is accepted for publication at <strong>EuroMPI/USA'17</strong>.!!
		<p><strong>5/2017 </strong>: I am appointed as Team Lead for Scalable Machine Learning at PNNL.
		<p><strong>4/2017 </strong>: Our open source release of MaTEx-TensorFlow is now available at MaTEx github page. Kudos to the MaTEx team members!!
		<p><strong>3/2017 </strong>: Our paper on <strong>ScalaFSM: Enabling Scalability-Sensitive Speculative Parallelization for FSM Computations</strong> is accepted by <strong>ICS'17</strong>!!.
		<p><strong>2/2017 </strong>: Our paper on <strong>Deep Learning on Computational Chemistry</strong> is accepted by <strong>JCC'17</strong>!!.
		<p><strong>2/2017 </strong>: Our paper on <strong>Comparing NVIDIA DGX-1/Pascal and Intel Knights Landing on Deep Learning Workloads</strong> is accepted by <strong>ParLearning'17</strong>!!.
		<p><strong>1/2017 </strong>: Our paper on <strong>Generating Performance Models for Irregular Applications</strong> is accepted by <strong>IPDPS'17</strong>!!.
		<p><strong>11/2016 </strong>: Our proposal on <strong>xGA: Global Arrays on Extreme Scale Architectures</strong> is accepted by <strong>Exascale Computing Program (ECP)</strong>.
		<p><strong>10/2016 </strong>: Our paper on <strong>Adaptive Neuron Apoptosis for Accelerating Deep Learning on Large Scale Systems</strong> is accepted at IEEE Conference on BigData'16.
		<p><strong>9/2016 </strong>: Our research on <strong>Convergence of Machine Learning and Deep Learning for HPC Modeling and Simulation</strong> is funded by Advanced Scientific Computing Research (ASCR)!!.
		<p><strong>9/2016 </strong>: Our paper on <strong>Fault Tolerant Frequent Pattern Mining</strong> is accepted at HiPC'16.
		<p><strong>9/2016 </strong>: Our proposal on <strong>Learning Control on Building Systems</strong> is accepted at Control of Complex Systems Initiative (CCSI).
		<p><strong>7/2016 </strong>: We have received <strong>Oak Ridge Director's Discretionary Award</strong> for conducting research on Extreme Scale Deep Learning algorithms with MaTEx.
		<p><strong>5/2016 </strong>: Our paper on <strong>Fault Tolerant Support Vector Machines</strong> is accepted at ICPP'16.
		<p><strong>4/2016 </strong>: I am serving as a PC member for NAS Conference and 
		reviewer for Computer and TPDS Jouranals.
<p><strong>3/2016 </strong>: We released our MaTEx with Distributed
		TensorFlow using MPI and a paper -- Distributed TensorFlow with MPI.
<p><strong>1/2016 </strong>: I am serving as a co-editor on a Parallel Computing (ParCo) special issue
<p><strong>12/2015 </strong>: A paper on Application Fault Modeling using Machine Learning accepted in IPDPS'16.
<p><strong>11/2015</strong>: Featured Presentation on Extreme Scale Machine Learning Research at DOE Booth @ SC'15.
<p><strong>11/2015</strong>: Invited Presentation on role of Interconnects in Machine Learning at Mellanox Booth @ SC'15.
<p><strong>11/2015</strong>: Akshay Venkatesh (Summer student - 2014) presented best student paper nominee @ SC'15. Kudos!
<p><strong>10/2015</strong>: Invited Presentation on Global Arrays at Japan LENS workshop
<p><strong>10/2015</strong>: Presented a PNNL wide talk on <strong> What can Large Scale Machine Learning do for you?</strong> 
<p><strong>9/2015</strong>: Paper Presentation in Cluster'15 on Extreme Scale Support Vector Machines
<p><strong>9/2015</strong>: Paper Presentation in Cluster'15 on Work Stealing based Frequent Pattern Mining
<p><strong>8/2015</strong>: Invited Presentation in MUG'15 on role of MPI in Large Scale Machine Learning
<p><strong>7/2015</strong>: Joint work with OSU on Machine Learning accepted for publication in OpenSHMEM Workshop
<p><strong>7/2015</strong>: Our SC'15 paper is nominated for best student paper!!
			
	</small>		
	<div class="box">
				<h2><small>Contact :</small></h2>
				<ul>
				<li></li>
                <!-- <li><img src="resource/em.gif" alt="email" width="130" height="14" /></li> -->
		<small>
		                <li>abhinav (DOT) vishnu (AT) amd (DOT) com
				</small>
				</ul>
	</div>


  <div class="box">
	   <div style="font-size: 0.8em;">Last updated: 9/2018</div>
	</div>
</div>
</div>
<p>&nbsp;</p>
</body>
</html>

